{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmgFW3RUhHo4+BLdXs7nRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leunseo/Deep_Learning_PROJECT/blob/main/hw02_LEEUNSEO_2021380535.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsaOfyjy3dg5",
        "outputId": "05f336a6-8dea-4305-a1f3-1fd124f25cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m102.4/111.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0 (from d2l)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.23.5)\n",
            "Collecting matplotlib==3.7.2 (from d2l)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l) (2.31.0)\n",
            "Collecting pandas==2.0.3 (from d2l)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from d2l)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l)\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (9.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.3->d2l)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.10)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.12.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.21)\n",
            "Installing collected packages: tzdata, scipy, qtpy, pyparsing, jedi, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.3\n",
            "    Uninstalling scipy-1.11.3:\n",
            "      Successfully uninstalled scipy-1.11.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import d2l"
      ],
      "metadata": {
        "id": "VF2RBMDXEAvN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mxnet install\n",
        "!pip install mxnet-cu112"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hq06ZH_2tzO",
        "outputId": "888fb6a3-749c-4c44-bde5-dd3e91f82d76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet-cu112\n",
            "  Downloading mxnet_cu112-1.9.1-py3-none-manylinux2014_x86_64.whl (499.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu112) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu112) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu112)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu112) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu112) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu112) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu112) (2023.7.22)\n",
            "Installing collected packages: graphviz, mxnet-cu112\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu112-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "root = '/content/drive/'\n",
        "drive.mount(root)\n",
        "\n",
        "# Change directory to '/content/drive/MyDrive/Colab Notebooks'\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "# Download d2l from the repository\n",
        "!git clone https://github.com/MLman/d2l-pytorch.git\n",
        "\n",
        "# Change directory to the d2l directory\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/d2l-pytorch/d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inO9HoopBREw",
        "outputId": "9a26d882-bb53-462a-c07c-0139eb1c5073"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            "fatal: destination path 'd2l-pytorch' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/d2l-pytorch/d2l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUpS_8tSEE_h",
        "outputId": "1a8e6d8c-af47-48a8-fe42-44a08d2c668d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/d2l-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_j3SI7oQ3-Zg"
      },
      "outputs": [],
      "source": [
        "#SSD\n",
        "%matplotlib inline\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "import d2l\n",
        "# from d2l.ssd_utils import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "def cls_predictor(input_channels, num_anchors, num_classes):\n",
        "    return nn.Conv2d(in_channels=input_channels, out_channels=num_anchors * (num_classes + 1), kernel_size=3,\n",
        "                     padding=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SSDLoss(nn.Module):\n",
        "\n",
        "   def one_hot_encoding(labels, num_classes):\n",
        "    return torch.eye(num_classes)[labels.cpu()]"
      ],
      "metadata": {
        "id": "OfxSvmP1yE1L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bounding Box Prediction Layer\n",
        "\n",
        "def bbox_predictor(input_channels, num_anchors):\n",
        "    return nn.Conv2d(in_channels=input_channels, out_channels=num_anchors * 4, kernel_size=3, padding=1)"
      ],
      "metadata": {
        "id": "_-lO_Rdo0bNf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x, block):\n",
        "    return block(x)\n",
        "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
        "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
        "(Y1.shape, Y2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RdFQEnj0mS2",
        "outputId": "6794453e-0c0b-4913-8a15-4bf8a0d6593c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_pred(pred):\n",
        "    return pred.permute(0, 2, 3, 1).reshape(pred.size(0),-1)\n",
        "\n",
        "def concat_preds(preds):\n",
        "    return torch.cat(tuple([flatten_pred(p) for p in preds]), dim=1)"
      ],
      "metadata": {
        "id": "pGIwvYgf0mVi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_preds([Y1, Y2]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr_JFhAh0mYZ",
        "outputId": "a1e2cfb3-15cc-40cd-dd59-37585dca1030"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 25300])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Height and Width Downsample Block\n",
        "def down_sample_blk(input_channels, num_channels):\n",
        "    blk = []\n",
        "    for _ in range(2):\n",
        "        blk.append(nn.Conv2d(in_channels=input_channels, out_channels=num_channels, kernel_size=3, padding=1))\n",
        "        blk.append(nn.BatchNorm2d(num_features=num_channels))\n",
        "        blk.append(nn.ReLU())\n",
        "        input_channels=num_channels\n",
        "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    blk = nn.Sequential(*blk)\n",
        "    return blk"
      ],
      "metadata": {
        "id": "RJ1chrWR0mbB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHEtZAEb0mdR",
        "outputId": "f2901510-b5ec-4323-e90e-d9e59ea6c464"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Network Block\n",
        "def base_net():\n",
        "    blk = []\n",
        "    num_filters = [3, 16, 32, 64]\n",
        "    for i in range(len(num_filters) - 1):\n",
        "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
        "    blk = nn.Sequential(*blk)\n",
        "    return blk\n",
        "\n",
        "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHoDkMZm0r2Z",
        "outputId": "d3ceed71-0a10-44fe-85c5-456f18c4d34a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The Complete Model\n",
        "\n",
        "def get_blk(i):\n",
        "    if i == 0:\n",
        "        blk = base_net()\n",
        "    elif i == 1:\n",
        "        blk = down_sample_blk(64, 128)\n",
        "    elif i == 4:\n",
        "        blk = nn.AdaptiveMaxPool2d((1,1))\n",
        "    else:\n",
        "        blk = down_sample_blk(128, 128)\n",
        "\n",
        "    return blk"
      ],
      "metadata": {
        "id": "yH48-5lc0r42"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import math\n",
        "def create_anchors(feature_map_sizes, steps, sizes):\n",
        "    \"\"\"Compute default box sizes with scale and aspect transform.\"\"\"\n",
        "    scale = 256.\n",
        "    steps = [s / scale for s in steps]\n",
        "    sizes = [s / scale for s in sizes]\n",
        "\n",
        "    aspect_ratios = ((2,),)\n",
        "\n",
        "\n",
        "    num_layers = len(feature_map_sizes)\n",
        "\n",
        "    boxes = []\n",
        "    for i in range(num_layers):\n",
        "        fmsize = feature_map_sizes[i]\n",
        "        for h, w in itertools.product(range(fmsize), repeat=2):\n",
        "            cx = (w + 0.5)*steps[i]\n",
        "            cy = (h + 0.5)*steps[i]\n",
        "            s = sizes[i]\n",
        "            boxes.append((cx, cy, s, s))\n",
        "\n",
        "            s = sizes[i+1]\n",
        "            boxes.append((cx, cy, s, s))\n",
        "\n",
        "            s = sizes[i]\n",
        "            for ar in aspect_ratios[i]:\n",
        "\n",
        "#                 boxes.append((cx - (s * math.sqrt(ar))/2, cy - (s / math.sqrt(ar))/2, cx + (s * math.sqrt(ar))/2, cy + (s / math.sqrt(ar))/2))\n",
        "#                 boxes.append((cx - (s / math.sqrt(ar))/2, cy - (s * math.sqrt(ar))/2, cx + (s / math.sqrt(ar))/2, cy + (s * math.sqrt(ar))/2))\n",
        "\n",
        "                boxes.append((cx, cy, (s * math.sqrt(ar)), (s / math.sqrt(ar))))\n",
        "                boxes.append((cx, cy, (s / math.sqrt(ar)), (s * math.sqrt(ar))))\n",
        "\n",
        "    return torch.Tensor(boxes) # [8632, 4]"
      ],
      "metadata": {
        "id": "8zk9x-ho0r8e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
        "    Y = blk(X)\n",
        "    anchors = create_anchors((Y.size(2),), (256/Y.size(2),), size)\n",
        "    cls_preds = cls_predictor(Y)\n",
        "    bbox_preds = bbox_predictor(Y)\n",
        "    return (Y, anchors, cls_preds, bbox_preds)"
      ],
      "metadata": {
        "id": "OVgK5J_y0r_U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [[0.2*256, 0.272*256], [0.37*256, 0.447*256], [0.54*256, 0.619*256],\n",
        "         [0.71*256, 0.79*256], [0.88*256, 0.961*256]]\n",
        "ratios = [[1, 2, 0.5]] * 5\n",
        "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
      ],
      "metadata": {
        "id": "QVNtb2RF01dP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinySSD(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(TinySSD, self).__init__()\n",
        "\n",
        "        input_channels_cls = 128\n",
        "        input_channels_bbox = 128\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.blk = []\n",
        "        self.cls = []\n",
        "        self.bbox = []\n",
        "\n",
        "        self.blk_0 = get_blk(0)\n",
        "        self.blk_1 = get_blk(1)\n",
        "        self.blk_2 = get_blk(2)\n",
        "        self.blk_3 = get_blk(3)\n",
        "        self.blk_4 = get_blk(4)\n",
        "\n",
        "        self.cls_0 = cls_predictor(64, num_anchors, num_classes)\n",
        "        self.cls_1 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
        "        self.cls_2 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
        "        self.cls_3 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
        "        self.cls_4 = cls_predictor(input_channels_cls, num_anchors, num_classes)\n",
        "\n",
        "        self.bbox_0 = bbox_predictor(64, num_anchors)\n",
        "        self.bbox_1 = bbox_predictor(input_channels_bbox, num_anchors)\n",
        "        self.bbox_2 = bbox_predictor(input_channels_bbox, num_anchors)\n",
        "        self.bbox_3 = bbox_predictor(input_channels_bbox, num_anchors)\n",
        "        self.bbox_4 = bbox_predictor(input_channels_bbox, num_anchors)\n",
        "\n",
        "    def forward(self, X):\n",
        "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
        "\n",
        "        X, anchors[0], cls_preds[0], bbox_preds[0] = blk_forward(X, self.blk_0, sizes[0], ratios[0],\n",
        "                                                                    self.cls_0, self.bbox_0)\n",
        "\n",
        "        X, anchors[1], cls_preds[1], bbox_preds[1] = blk_forward(X, self.blk_1, sizes[1], ratios[1],\n",
        "                                                                    self.cls_1, self.bbox_1)\n",
        "\n",
        "        X, anchors[2], cls_preds[2], bbox_preds[2] = blk_forward(X, self.blk_2, sizes[2], ratios[2],\n",
        "                                                                    self.cls_2, self.bbox_2)\n",
        "\n",
        "        X, anchors[3], cls_preds[3], bbox_preds[3] = blk_forward(X, self.blk_3, sizes[3], ratios[3],\n",
        "                                                                    self.cls_3, self.bbox_3)\n",
        "\n",
        "        X, anchors[4], cls_preds[4], bbox_preds[4] = blk_forward(X, self.blk_4, sizes[4], ratios[4],\n",
        "                                                                    self.cls_4, self.bbox_4)\n",
        "\n",
        "        return (torch.cat(anchors, dim=0), concat_preds(cls_preds).reshape((-1, 5444, self.num_classes + 1)),\n",
        "                concat_preds(bbox_preds))"
      ],
      "metadata": {
        "id": "u-ieznyryqQn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5"
      ],
      "metadata": {
        "id": "9ZDEPRuL01hk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "net = TinySSD(3, num_classes=1)\n",
        "net.apply(init_weights)\n",
        "\n",
        "X = torch.zeros((32, 3, 256, 256))\n",
        "anchors, cls_preds, bbox_preds = net(X)\n",
        "\n",
        "print('output anchors:', anchors.shape)\n",
        "print('output class preds:', cls_preds.shape)\n",
        "print('output bbox preds:', bbox_preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjtBzHCW05XY",
        "outputId": "969e1333-1ef4-4ef7-a3c6-69822daf2f0d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output anchors: torch.Size([5444, 4])\n",
            "output class preds: torch.Size([32, 5444, 2])\n",
            "output bbox preds: torch.Size([32, 21776])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "#Data Reading and Initialization\n",
        "\n",
        "#d2l.download_and_preprocess_data()"
      ],
      "metadata": {
        "id": "_HCgc6WNE7LL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qNA0fUqKEXCU",
        "outputId": "f06ea43d-f17a-41a3-c7c5-de9c1ae93a7f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/d2l-pytorch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "data_dir = './data/pikachu/'\n",
        "train_dataset = d2l.PIKACHU(data_dir, 'train')\n",
        "val_dataset = d2l.PIKACHU(data_dir, 'val')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           num_workers=4)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                         batch_size=batch_size, shuffle=False,\n",
        "                                         num_workers=4)"
      ],
      "metadata": {
        "id": "tr1aglq806da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "9ef9cf0f-89a8-47d7-a486-bd178a966180"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1bf6694b09ca>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/pikachu/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIKACHU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIKACHU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'd2l' has no attribute 'PIKACHU'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '7' # You can set gpu no. if you have multiple gpus"
      ],
      "metadata": {
        "id": "AYUBCr-Y08ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "5UK_hUbp0-P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TinySSD(3, num_classes=1)\n",
        "net.apply(init_weights)\n",
        "net = net.to(device)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 5e-4\n",
        "optimizer = optim.SGD(net.parameters(), lr = learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "PD9y52a_0-SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Loss and Evaluation Functions\n",
        "id_cat = dict()\n",
        "id_cat[0] = 'pikachu'\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2, device=\"cuda:0\", eps=1e-10):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.device = device\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        p = torch.sigmoid(input)\n",
        "        pt = p * target.float() + (1.0 - p) * (1 - target).float()\n",
        "        alpha_t = (1.0 - self.alpha) * target.float() + self.alpha * (1 - target).float()\n",
        "        loss = - 1.0 * torch.pow((1 - pt), self.gamma) * torch.log(pt + self.eps)\n",
        "        return loss.sum()\n",
        "\n",
        "class SSDLoss(nn.Module):\n",
        "    def __init__(self, loc_factor, jaccard_overlap, device = \"cuda:0\", **kwargs):\n",
        "        super().__init__()\n",
        "        self.fl = FocalLoss(**kwargs)\n",
        "        self.loc_factor = loc_factor\n",
        "        self.jaccard_overlap = jaccard_overlap\n",
        "\n",
        "\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "    def one_hot_encoding(labels, num_classes):\n",
        "        return torch.eye(num_classes)[labels]\n",
        "\n",
        "    def loc_transformation(x, anchors, overlap_indicies):\n",
        "        # Doing location transformations according to SSD paper\n",
        "        return torch.cat([(x[:, 0:1] - anchors[overlap_indicies, 0:1]) / anchors[overlap_indicies, 2:3],\n",
        "                          (x[:, 1:2] - anchors[overlap_indicies, 1:2]) / anchors[overlap_indicies, 3:4],\n",
        "                          torch.log((x[:, 2:3] / anchors[overlap_indicies, 2:3])),\n",
        "                          torch.log((x[:, 3:4] / anchors[overlap_indicies, 3:4]))\n",
        "                         ], dim=1)\n",
        "\n",
        "    def forward(self, class_hat, bb_hat, class_true, bb_true, anchors):\n",
        "        loc_loss = 0.0\n",
        "        class_loss = 0.0\n",
        "\n",
        "\n",
        "        for i in range(len(class_true)):  # Batch level\n",
        "\n",
        "            class_hat_i = class_hat[i, :, :]\n",
        "\n",
        "            bb_true_i = bb_true[i].float()\n",
        "\n",
        "            class_true_i = class_true[i]\n",
        "\n",
        "            class_target = torch.zeros(class_hat_i.shape[0]).long().to(self.device)\n",
        "\n",
        "            overlap_list = d2l.find_overlap(bb_true_i.squeeze(0), anchors, self.jaccard_overlap)\n",
        "\n",
        "            temp_loc_loss = 0.0\n",
        "            for j in range(len(overlap_list)):  # BB level\n",
        "                overlap = overlap_list[j]\n",
        "                class_target[overlap] = class_true_i[0, j].long()\n",
        "\n",
        "                input_ = bb_hat[i, overlap, :]\n",
        "                target_ = SSDLoss.loc_transformation(bb_true_i[0, j, :].expand((len(overlap), 4)), anchors, overlap)\n",
        "\n",
        "                temp_loc_loss += F.smooth_l1_loss(input=input_, target=target_, reduction=\"sum\") / len(overlap)\n",
        "            loc_loss += temp_loc_loss / class_true_i.shape[1]\n",
        "\n",
        "            class_target = SSDLoss.one_hot_encoding(class_target, len(id_cat) + 1).float().to(self.device)\n",
        "            class_loss += self.fl(class_hat_i, class_target) / class_true_i.shape[1]\n",
        "\n",
        "        loc_loss = loc_loss / len(class_true)\n",
        "        class_loss = class_loss / len(class_true)\n",
        "        loss = class_loss + loc_loss * self.loc_factor\n",
        "\n",
        "        return loss, loc_loss, class_loss"
      ],
      "metadata": {
        "id": "833mUVWX1ADt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "\n",
        "loss = SSDLoss(loc_factor=5.0, jaccard_overlap=0.5, device=\"cuda:0\")"
      ],
      "metadata": {
        "id": "_73Pec6A1AeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "init_epoch = 0\n",
        "\n",
        "# Uncomment the following 2 lines if you wish to load a pre-trained/saved model\n",
        "checkpoint_path = './ssd_outputs/model-29_0.1411931432526687.pth'   # Mention the model name to load\n",
        "init_epoch = d2l.load(net, checkpoint_path, optimizer)\n",
        "\n",
        "animator = d2l.Animator(xlabel='epoch', xlim=[init_epoch+1, num_epochs],\n",
        "                        legend=['class error', 'bbox mae', 'train_err'])\n",
        "\n",
        "for epoch in range(init_epoch, num_epochs):\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    loc_loss = 0.0\n",
        "    class_loss = 0.0\n",
        "\n",
        "    for i, (x, bb_true, class_true) in (enumerate(train_loader)):\n",
        "\n",
        "        x = x.to(device)\n",
        "        bb_true = bb_true.to(device)\n",
        "        class_true = class_true.to(device)\n",
        "\n",
        "        timer_start = time.time()\n",
        "\n",
        "        anchors, cls_preds, bbox_preds = net(x)\n",
        "\n",
        "        class_true = [*class_true.reshape((class_true.size(0), 1, 1))]\n",
        "        bb_true = [*bb_true.reshape((bb_true.size(0), 1, 1, 4))]\n",
        "\n",
        "        bbox_preds = bbox_preds.reshape((-1, 5444, 4))\n",
        "\n",
        "        # Label the category and offset of each anchor box\n",
        "\n",
        "        anchors = anchors.to(device)\n",
        "\n",
        "        batch_loss, batch_loc_loss, batch_class_loss = loss(cls_preds, bbox_preds, class_true, bb_true, anchors)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        class_loss += batch_class_loss\n",
        "        loc_loss += batch_loc_loss\n",
        "        train_loss += batch_loss\n",
        "\n",
        "#     Uncomment the following 2 line for saving the model every epoch\n",
        "#     path_to_checkpoints_dir = './ssd_outputs/'\n",
        "#     d2l.save(net, path_to_checkpoints_dir, epoch, optimizer, train_loss/len(train_loader))\n",
        "\n",
        "    train_loss = (train_loss/len(train_loader)).detach().cpu().numpy()\n",
        "    loc_loss = (loc_loss/len(train_loader)).detach().cpu().numpy()\n",
        "    class_loss = (class_loss/len(train_loader)).detach().cpu().numpy()\n",
        "\n",
        "#     print(class_loss, loc_loss, train_loss, epoch+1)\n",
        "\n",
        "    # Uncomment the following if you wish to see the results after every epoch to see the learning effect\n",
        "    # Images will be saved to the 'results_every_epoch' directory\n",
        "\n",
        "#     try:\n",
        "#         d2l.infer(net, epoch, 0.9, device)\n",
        "#     except Exception as e:\n",
        "#         print(e, 'error' + str(epoch+1))\n",
        "\n",
        "\n",
        "    animator.add(epoch, (class_loss, loc_loss, train_loss))"
      ],
      "metadata": {
        "id": "wWAv0tli1Agl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the final Model\n",
        "path_to_checkpoints_dir = './ssd_outputs'\n",
        "d2l.save(net, path_to_checkpoints_dir, epoch, optimizer, train_loss/len(train_loader))"
      ],
      "metadata": {
        "id": "-lv2_LjF1Ajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "img = np.array(Image.open('../img/pikachu.jpg').convert('RGB').resize((256, 256), Image.BILINEAR))\n",
        "X = transforms.Compose([transforms.ToTensor()])(img).to(device)\n",
        "X = X.to(device)"
      ],
      "metadata": {
        "id": "Yh1LjMd-1Ggq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, nms_threshold):\n",
        "    background_threshold = 0.8\n",
        "    net.eval()\n",
        "    anchors, class_hat, bb_hat = net(X.unsqueeze(0))\n",
        "    anchors = anchors.to(device)\n",
        "    bb_hat = bb_hat.reshape((1, -1, 4))\n",
        "    bb_hat = d2l.invert_transformation(bb_hat.squeeze(0), anchors)\n",
        "    bb_hat = bb_hat * 256.0\n",
        "\n",
        "    class_hat = class_hat.sigmoid().squeeze(0)\n",
        "\n",
        "    bb_hat = bb_hat[class_hat[:,0] < background_threshold, :]\n",
        "\n",
        "\n",
        "    bb_hat = bb_hat.detach().cpu().numpy()\n",
        "    class_hat = class_hat[class_hat[:,0] < background_threshold, :]\n",
        "\n",
        "    class_preds = class_hat[:, 1:]\n",
        "\n",
        "    prob, class_id = torch.max(class_preds,1)\n",
        "\n",
        "    prob = prob.detach().cpu().numpy()\n",
        "    class_id = class_id.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "    output_bb = [d2l.PredBoundingBox(probability=1 - prob[i],\n",
        "                                 class_id=class_id[i],\n",
        "                                 classname=id_cat[class_id[i]],\n",
        "                                 bounding_box=[bb_hat[i, 0],\n",
        "                                               bb_hat[i, 1],\n",
        "                                               bb_hat[i, 2],\n",
        "                                               bb_hat[i, 3]])\n",
        "                                 for i in range(0, len(prob))]\n",
        "\n",
        "    output_bb = sorted(output_bb, key = lambda x: x.probability, reverse=False)\n",
        "\n",
        "    filtered_bb = d2l.non_max_suppression(output_bb, nms_threshold)\n",
        "\n",
        "    return filtered_bb\n",
        "\n",
        "filtered_bb = predict(X, 0.1)"
      ],
      "metadata": {
        "id": "z0d8mkst1JC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(img, output):\n",
        "\n",
        "    img = d2l.draw_boxes(img, [bb.bounding_box for bb in filtered_bb])\n",
        "    img = d2l.draw_text(img, [str(bb.probability)[:5] for bb in filtered_bb], [bb.bounding_box for bb in filtered_bb])\n",
        "    d2l.plt.imshow(img)\n",
        "    d2l.plt.show()\n",
        "\n",
        "display(img, filtered_bb)"
      ],
      "metadata": {
        "id": "9cCI-oKh1JFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercises\n",
        "#Loss Function\n",
        "sigmas = [10, 1, 0.5]\n",
        "lines = ['-', '--', '-.']\n",
        "x = np.arange(-2, 2, 0.1)\n",
        "d2l.set_figsize()"
      ],
      "metadata": {
        "id": "MeFpgiI_1JHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_l1(x, scalar):\n",
        "    a = []\n",
        "    for i in x:\n",
        "\n",
        "        if abs(i) < 1/((scalar)**2):\n",
        "            a.append(((scalar*i)**2)/2)\n",
        "\n",
        "        else:\n",
        "            a.append(abs(i) - 0.5/((scalar)**2))\n",
        "\n",
        "    return np.array(a)"
      ],
      "metadata": {
        "id": "YpK3ezFE1S53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = []\n",
        "for l, s in zip(lines, sigmas):\n",
        "    y = smooth_l1(x, scalar=s)\n",
        "    d2l.plt.plot(x, y, l, label='sigma=%.1f' % s)\n",
        "\n",
        "d2l.plt.legend();"
      ],
      "metadata": {
        "id": "hpM4LEp41S7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(gamma, x):\n",
        "    return -(1 - x) ** gamma * np.log(x)\n",
        "\n",
        "x = np.arange(0.01, 1, 0.01)\n",
        "\n",
        "for l, gamma in zip(lines, [0, 1, 5]):\n",
        "    y = d2l.plt.plot(x, focal_loss(gamma, x), l,\n",
        "                     label='gamma=%.1f' % gamma)\n",
        "\n",
        "d2l.plt.legend();"
      ],
      "metadata": {
        "id": "VOHOBmST1Vvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}